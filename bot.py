import os
import asyncio
import logging
import base64
import requests
import tempfile

from dotenv import load_dotenv
from openai import OpenAI

from aiogram import Bot, Dispatcher, F
from aiogram.enums import ParseMode
from aiogram.types import Message

from flask import Flask
from hypercorn.asyncio import serve
from hypercorn.config import Config

# ---------- ENV ----------
load_dotenv()
TG_TOKEN = os.getenv("TELEGRAM_BOT_TOKEN")
OPENAI_KEY = os.getenv("OPENAI_API_KEY")
MODEL = os.getenv("OPENAI_MODEL", "gpt-4o-mini")  # —É–º–µ–µ—Ç vision
PORT = int(os.getenv("PORT", "10000"))

if not TG_TOKEN:
    raise RuntimeError("TELEGRAM_BOT_TOKEN –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç")
if not OPENAI_KEY:
    raise RuntimeError("OPENAI_API_KEY –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç")

# OpenAI
os.environ["OPENAI_API_KEY"] = OPENAI_KEY
client = OpenAI()

# ---------- LOGGING ----------
logging.basicConfig(level=logging.INFO, format="%(asctime)s %(levelname)s %(message)s")
log = logging.getLogger("fixfur-bot")

# ---------- Aiogram ----------
bot = Bot(token=TG_TOKEN, parse_mode=ParseMode.HTML)
dp = Dispatcher()

SYSTEM_PROMPT = (
    "–¢—ã ‚Äî –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç –ø—Ä–µ–º–∏–∞–ª—å–Ω–æ–≥–æ –º–µ—Ö–æ–≤–æ–≥–æ –∞—Ç–µ–ª—å–µ ¬´FIX FUR by ATARSHCHIKOV¬ª. "
    "–¢–æ–Ω ‚Äî –ø—Ä–µ–º–∏–∞–ª—å–Ω—ã–π, —É–≤–µ—Ä–µ–Ω–Ω—ã–π –∏ –ø–æ –¥–µ–ª—É. –î–∞–≤–∞–π —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –ø–µ—Ä–µ—à–∏–≤—É, —Ä–µ—Å—Ç–∞–≤—Ä–∞—Ü–∏–∏ –∏ —É—Ö–æ–¥—É."
)

def chunk(text: str, size: int = 3500):
    for i in range(0, len(text), size):
        yield text[i:i+size]

# ===== helpers =====
def openai_text_reply(prompt: str) -> str:
    resp = client.chat.completions.create(
        model=MODEL,
        messages=[
            {"role": "system", "content": SYSTEM_PROMPT},
            {"role": "user", "content": prompt},
        ],
        temperature=0.5,
        max_tokens=700,
    )
    return resp.choices[0].message.content.strip()

def openai_vision_reply(image_bytes: bytes, user_prompt: str) -> str:
    data_url = "data:image/jpeg;base64," + base64.b64encode(image_bytes).decode("utf-8")
    resp = client.chat.completions.create(
        model=MODEL,  # gpt-4o-mini –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –∫–∞—Ä—Ç–∏–Ω–∫–∏
        messages=[
            {"role": "system", "content": SYSTEM_PROMPT},
            {
                "role": "user",
                "content": [
                    {"type": "text", "text": user_prompt},
                    {"type": "image_url", "image_url": {"url": data_url}},
                ],
            },
        ],
        temperature=0.5,
        max_tokens=700,
    )
    return resp.choices[0].message.content.strip()

# ===== handlers =====
@dp.message(F.text == "/start")
async def on_start(message: Message):
    welcome = (
        "–î–æ–±—Ä–æ –ø–æ–∂–∞–ª–æ–≤–∞—Ç—å –≤ <b>FIX FUR by ATARSHCHIKOVI</b> üß•\n"
        "–ó–∞–¥–∞–π—Ç–µ –≤–æ–ø—Ä–æ—Å –æ —Ä–µ—Å—Ç–∞–≤—Ä–∞—Ü–∏–∏, –ø–µ—Ä–µ—à–∏–≤–µ, —Ö—Ä–∞–Ω–µ–Ω–∏–∏ –∏–ª–∏ —É—Ö–æ–¥–µ ‚Äî –ø–æ–¥—Å–∫–∞–∂—É –ª—É—á—à–∏–π –≤–∞—Ä–∏–∞–Ω—Ç."
    )
    await message.answer(welcome)

@dp.message(F.text & ~F.text.startswith("/"))
async def on_text(message: Message):
    user_text = message.text or ""
    try:
        reply = await asyncio.to_thread(openai_text_reply, user_text)
    except Exception as e:
        reply = f"–ò–∑–≤–∏–Ω–∏—Ç–µ, –≤—Ä–µ–º–µ–Ω–Ω–∞—è –æ—à–∏–±–∫–∞: {e}"
    for part in chunk(reply):
        await message.answer(part)

# –§–æ—Ç–æ (jpg/png) –∫–∞–∫ photo –∏–ª–∏ –∫–∞–∫ –¥–æ–∫—É–º–µ–Ω—Ç-–∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
@dp.message(F.photo | (F.document & F.document.mime_type.startswith("image/")))
async def on_photo(message: Message):
    try:
        caption = message.caption or (
            "–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∫–∞–∫ –º–∞—Å—Ç–µ—Ä –º–µ—Ö–æ–≤–æ–≥–æ –∞—Ç–µ–ª—å–µ: —Å–æ—Å—Ç–æ—è–Ω–∏–µ –º–µ—Ö–∞, –≤–∏–¥–∏–º—ã–µ –¥–µ—Ñ–µ–∫—Ç—ã, –≤–∞—Ä–∏–∞–Ω—Ç—ã —Ä–∞–±–æ—Ç –∏ —É—Ö–æ–¥."
        )
        # –±–µ—Ä—ë–º —Å–∞–º–æ–µ –±–æ–ª—å—à–æ–µ –ø—Ä–µ–≤—å—é –∏–ª–∏ —Å–∞–º –¥–æ–∫—É–º–µ–Ω—Ç
        if getattr(message, "photo", None):
            file_id = message.photo[-1].file_id
        else:
            file_id = message.document.file_id

        tg_file = await bot.get_file(file_id)
        file_url = f"https://api.telegram.org/file/bot{TG_TOKEN}/{tg_file.file_path}"
        img_bytes = requests.get(file_url, timeout=60).content

        reply = await asyncio.to_thread(openai_vision_reply, img_bytes, caption)
    except Exception as e:
        reply = f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å —Ñ–æ—Ç–æ: {e}"
    await message.answer(reply)

# –ì–æ–ª–æ—Å–æ–≤—ã–µ (ogg/oga) ‚Üí Whisper ‚Üí –æ—Ç–≤–µ—Ç
@dp.message(F.voice | (F.document & F.document.mime_type == "audio/ogg"))
async def on_voice(message: Message):
    try:
        file = await bot.get_file(message.voice.file_id if message.voice else message.document.file_id)
        file_url = f"https://api.telegram.org/file/bot{TG_TOKEN}/{file.file_path}"
        r = requests.get(file_url, timeout=60)
        r.raise_for_status()
        with tempfile.NamedTemporaryFile(suffix=".ogg", delete=False) as tmp:
            tmp.write(r.content)
            tmp_path = tmp.name
        with open(tmp_path, "rb") as f:
            tr = client.audio.transcriptions.create(model="whisper-1", file=f)
        user_text = (tr.text if hasattr(tr, "text") else tr["text"]).strip()
        reply = await asyncio.to_thread(openai_text_reply, user_text)
        await message.answer(f"–†–∞—Å—à–∏—Ñ—Ä–æ–≤–∫–∞: ¬´{user_text}¬ª\n\n{reply}")
    except Exception as e:
        await message.answer(f"–ù–µ —É–¥–∞–ª–æ—Å—å –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å –≥–æ–ª–æ—Å–æ–≤–æ–µ: {e}")

# ---------- Flask (healthcheck –¥–ª—è Render) ----------
app = Flask(__name__)

@app.get("/")
def health():
    return "ok", 200

async def run_flask():
    cfg = Config()
    cfg.bind = [f"0.0.0.0:{PORT}"]
    await serve(app, cfg)

async def run_aiogram():
    # —Ñ–∏–∫—Å –∫–æ–Ω—Ñ–ª–∏–∫—Ç–æ–≤ polling: —Å–±—Ä–∞—Å—ã–≤–∞–µ–º –≤–µ–±—Ö—É–∫ –∏ –≤–∏—Å—è—â–∏–µ –∞–ø–¥–µ–π—Ç—ã
    await bot.delete_webhook(drop_pending_updates=True)
    await dp.start_polling(bot)

# ---------- Entry ----------
async def main():
    await asyncio.gather(run_aiogram(), run_flask())

if __name__ == "__main__":
    asyncio.run(main())
